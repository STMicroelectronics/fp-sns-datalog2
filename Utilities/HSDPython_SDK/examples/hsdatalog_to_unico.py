#!/usr/bin/env python
# coding: utf-8 
# *****************************************************************************
#  * @file    hsdatalog_to_unico.py
#  * @author  SRA
# ******************************************************************************
# * @attention
# *
# * Copyright (c) 2022 STMicroelectronics.
# * All rights reserved.
# *
# * This software is licensed under terms that can be found in the LICENSE file
# * in the root directory of this software component.
# * If no LICENSE file comes with this software, it is provided AS-IS.
# *
# *
# ******************************************************************************
#

"""
This script, `hsdatalog_to_unico.py`, is designed to convert data from acquisition folders
generated by STMicroelectronics' HSDatalog tool into a format compatible with ST MEMS Studio.
It supports various options for customizing the data conversion, including selecting specific sensors,
setting time ranges, specifying output formats, aggregating exported data and more.
It uses Click for command-line interface options and logs information and errors during execution.
The script can be run from the command line with various options to tailor the data conversion
to the user's needs.

Key Features:
- Convert data for specific sensors or all active components.
- Set start and end times for the data conversion.
- Specify the output format (TXT, CSV, TSV).
- Option to convert raw data (not multiplied by sensitivity).
- Include annotations in the exported data (if any in the acquisition folder).
- Include data sections without tags in the exported output ("untagged" folder).
- Aggregate data into a single file or split data per tags (if any in the acquisition folder).
- Use different naming conventions for column names in exported files ('default', 'mlc_tool').
- Specify the size of each data chunk to be processed.
- Upload and use a custom Device Template Model (DTDL).
- Enable debug mode to check for corrupted data and timestamps.
"""

import os
import click

from st_hsdatalog.HSD_utils.dtm import HSDatalogDTM
from st_hsdatalog.HSD_utils.exceptions import MissingDeviceModelError, MissingISPUOutputDescriptorException, MissingTagsException
import st_hsdatalog.HSD_utils.logger as logger
from st_hsdatalog.HSD.HSDatalog import HSDatalog

# Set up the application logger to record debug information and errors
log = logger.setup_applevel_logger(is_debug = False, file_name= "app_debug.log")

# Define the script version for reference
script_version = "2.1.0"

# Define a callback function to show help information and example usage of the script
def show_help(ctx, param, value):
    # Display the help information for the command
    if value and not ctx.resilient_parsing:
        # Display examples of script execution
        click.secho(ctx.get_help(), color=ctx.color)
        click.secho("\n-> Script execution examples:")
        # Extract data for all active sensors from the specified acquisition folder and save it in the default output format.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -s all", fg='cyan')
        # Extract data for all active sensors and save it in CSV format in the specified output folder.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -o Output_Folder_Path -f CSV -s all", fg='cyan')
        # Extract data for a specific sensor named SENSOR_NAME and save it in the default output format.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -s SENSOR_NAME", fg='cyan')
        # Extract data for the sensor SENSOR_NAME, starting from 3 seconds and ending at 6 seconds, and include timestamps in the output.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -st 3 -et 6 -wt -s SENSOR_NAME", fg='cyan')
        # Extract data for all active sensors and include annotations in the exported data.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -t -s all", fg='cyan')
        # Upload a custom Device Template Model (DTDL) "custom_model.json" with board_id=0xff, fw_id=0xff and extract data for the sensor SENSOR_NAME.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -cdm 255 255 custom_model.json -s SENSOR_NAME", fg='cyan')
        # Specify the size of each data chunk to be 1000 samples for the sensor SENSOR_NAME.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -cs 1000 -s SENSOR_NAME", fg='cyan')
        # Extract data for all active sensors, aggregate the data into a single file, and save it in CSV format.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -ag single_file -f CSV -s all", fg='cyan')
        # Extract data for all active sensors, aggregate the data into a single file, and save it in TXT format.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -ag single_file -f TXT -s all", fg='cyan')
        # Extract raw data (not multiplied by sensitivity) for the sensor SENSOR_NAME and save it in CSV format.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -r -f CSV -s SENSOR_NAME", fg='cyan')
        # Extract data for all active sensors, split the data per tags, and include untagged data sections in the output files.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -ag split_per_tags -wu -s all", fg='cyan')
        # Extract data for all active sensors using the 'mlc_tool' naming convention for column names in the exported files.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -cl mlc_tool -s all", fg='cyan')
        # Extract data for all active sensors, split the data per tags, using the 'mlc_tool' naming convention for column names in the exported files and including untagged data sections in the output files.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -ag split_per_tags -wu -cl mlc_tool -s all", fg='cyan')
        # Run the script in debug mode to check for corrupted data and timestamps.
        click.secho("   python hsdatalog_to_unico.py Acquisition_Folder_Path -d -s SENSOR_NAME", fg='cyan')
        # Exit the context after showing help
        ctx.exit()

@click.command()
@click.argument('acq_folder', type=click.Path(exists=True))
@click.option('-o', '--output_folder', help="Output folder (this will be created if it doesn't exist)")
@click.option('-s', '--sensor_name', help="Sensor Name - use \"all\" to extract all active sensors data, otherwise select a specific sensor by name", default='all')
@click.option('-st','--start_time', help="Start Time - Data conversion will start from this time (seconds)", type=int, default=0)
@click.option('-et','--end_time', help="End Time - Data conversion will end up in this time (seconds)", type=int, default=-1)
@click.option('-t', '--use_datalog_tags', is_flag=True, help="Enable this flag to include information about annotations taken during acquisition (if any) in the exported data", default=False)
@click.option('-f', '--out_format', help="Select exported data format", type=click.Choice(['TXT', 'CSV', 'TSV'], case_sensitive=False))
@click.option('-wu', '--with_untagged', help="[NOTE: Valid only with -ag split_per_tags is selected] Select to export also untagged data sections in output files", is_flag=True, default=False)
@click.option('-wt','--with_timestamps', help="Enable this option to add timestamps column in the exported output files", is_flag=True, default=False)
@click.option('-r', '--raw_data', is_flag=True, help="Uses Raw data (not multiplied by sensitivity)", default=False)
@click.option('-cdm','--custom_device_model', help="Upload a custom Device Template Model (DTDL)", type=(int, int, str))
@click.option('-ag','--aggregation', help="Data aggregation strategy, exported data format remains selectable by using -f parameter (default value: CSV)",  type=click.Choice(['single_file', 'split_per_tags']))
@click.option('-cl','--columns_labels', help="Select the naming convention to be used when creating column names in exported files",  type=click.Choice(['default', 'mlc_tool']), default='default')
@click.option('-cs', '--chunk_size', help="Specify the size (number of samples) of each data chunk to be processed", default=HSDatalog.DEFAULT_SAMPLES_CHUNK_SIZE)
@click.version_option(script_version, '-v', '--version', prog_name="HSDatalogToUnico", is_flag=True, help="HSDatalogToUnico Converter tool version number")
@click.option('-d', '--debug', is_flag=True, help="[DEBUG] Check for corrupted data and timestamps", default=False)
@click.option("-h", "--help", is_flag=True, is_eager=True, expose_value=False, callback=show_help, help="Show this message and exit.",)

# Define the main function that will be executed when the script is run
def hsd_toUnico(acq_folder, output_folder, sensor_name, start_time, end_time, use_datalog_tags, out_format, raw_data, with_untagged, with_timestamps, custom_device_model, aggregation, columns_labels, chunk_size, debug):

    # If a custom device model is provided, upload it
    if custom_device_model is not None:
        HSDatalogDTM.upload_custom_dtm(custom_device_model)
    
    # Create an instance of the HSDatalog factory
    hsd_factory = HSDatalog()
    try:
        # Create an HSDatalog object for the given acquisition folder
        hsd = hsd_factory.create_hsd(acq_folder)
    except MissingDeviceModelError as error:
        # Handle the case where the device model is missing
        log.error("Device Template Model identifyed by [{}] not supported".format(error))
        log.info("Check your input acquisition folder, then try to upload a custom Device Template Model using -cdm flag".format(error))
        return

    # Set the default output format if not specified
    if out_format is None:
        out_format = 'csv'

    # Set the default output folder if not specified
    output_folder = acq_folder + "_Exported" if output_folder is None else output_folder
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Main loop to process data export by tags
    df_flag = True
    while df_flag:
        if aggregation is not None:
            convert_aggregated_data(hsd, aggregation, start_time, end_time, use_datalog_tags, output_folder, out_format, columns_labels, with_timestamps, with_untagged, raw_data, chunk_size)
            df_flag = False
        else:
            # If 'all' is specified for sensor name, process all active components
            if sensor_name == 'all':
                component_list = HSDatalog.get_all_components(hsd, only_active=True)
                for component in component_list:
                    sensor = __get_sensor_comp(hsd, component)
                    convert_data(hsd, sensor, start_time, end_time, use_datalog_tags, output_folder, out_format, columns_labels, with_timestamps, raw_data, chunk_size)
                df_flag = False
            # If a specific sensor name is provided, process only that component
            else:
                component = HSDatalog.get_component(hsd, sensor_name)
                if component is not None:
                    sensor = __get_sensor_comp(hsd, component)
                    convert_data(hsd, sensor, start_time, end_time, use_datalog_tags, output_folder, out_format, columns_labels, with_timestamps, raw_data, chunk_size)
                else:
                    # Log an error if the specified component is not found
                    log.error("No \"{}\" Component found in your Device Configuration file.".format(sensor_name))
                df_flag = False

# Define a helper function to get the sensor component
def __get_sensor_comp(hsd, component):
    sensor_name = list(component.keys())[0].split('_')[:-1][0].upper()
    s_list = HSDatalog.get_all_components(hsd, only_active=True)
    return HSDatalog.filter_sensor_list_by_name(hsd, sensor_name, s_list)

# Define a helper function to convert aggregated data
def convert_aggregated_data(hsd, aggregation, start_time, end_time, use_datalog_tags, output_folder, out_format, columns_labels="default", with_timestamps = False, with_untagged = False, raw_data=False, chunk_size = HSDatalog.DEFAULT_SAMPLES_CHUNK_SIZE):
    HSDatalog.convert_dat_to_unico_aggregated(hsd, aggregation, start_time, end_time, use_datalog_tags, output_folder, out_format, columns_labels, with_timestamps, with_untagged, raw_data, chunk_size)

# Define a helper function to convert data for a single sensor
def convert_data(hsd, sensor, start_time, end_time, use_datalog_tags, output_folder, out_format, columns_labels = "default", with_timestamps=False, raw_data=False, chunk_size = HSDatalog.DEFAULT_SAMPLES_CHUNK_SIZE):
    try:
        # Attempt to convert data to ST Unico format
        df = HSDatalog.convert_dat_to_unico(hsd, sensor, start_time, end_time, use_datalog_tags, output_folder, out_format, columns_labels, with_timestamps, raw_data, chunk_size)
        return df
    except MissingISPUOutputDescriptorException as ispu_err:
        # Handle missing ISPU output descriptor exception
        log.error(ispu_err)
        log.error(f"Copy the right ISPU output descriptor file in your \"{hsd.get_acquisition_path()}\" acquisition folder renamed as \"ispu_output_format.json\"")
    except MissingTagsException as tags_err:
        log.error(tags_err)
        log.error(f"Please check the tags field in your \"{os.path.join(hsd.get_acquisition_path(),'acquisition_info.json')}\" file.")
        quit()
    except Exception as err:
        log.exception(err)

if __name__ == '__main__':
    # Execute the main function
    hsd_toUnico()

